{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
      "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
      "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
      "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
      "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
      "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
      "\n",
      "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
      "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
      "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
      "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
      "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "\n",
      "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0         2   2008        WD         Normal     208500  \n",
      "1         5   2007        WD         Normal     181500  \n",
      "2         9   2008        WD         Normal     223500  \n",
      "3         2   2006        WD        Abnorml     140000  \n",
      "4        12   2008        WD         Normal     250000  \n",
      "...     ...    ...       ...            ...        ...  \n",
      "1455      8   2007        WD         Normal     175000  \n",
      "1456      2   2010        WD         Normal     210000  \n",
      "1457      5   2010        WD         Normal     266500  \n",
      "1458      4   2010        WD         Normal     142125  \n",
      "1459      6   2008        WD         Normal     147500  \n",
      "\n",
      "[1460 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "from settings import DATA_ROOT, CATEGORICAL_COLS, FLOAT_COLS, RESPONSE, RESULTS_DIR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(DATA_ROOT / \"train.csv\")\n",
    "test = pd.read_csv(DATA_ROOT / \"test.csv\")\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = train[CATEGORICAL_COLS].astype(str)\n",
    "cat_test = test[CATEGORICAL_COLS].astype(str)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_data = pd.concat([cat_train, cat_test], axis=0)\n",
    "# for encoder in encoders:\n",
    "#     encoder.fit(enc_data)\n",
    "\n",
    "X_num = train[FLOAT_COLS].astype(float).fillna(0.)\n",
    "X_cat = train[CATEGORICAL_COLS].astype(str).fillna(\"\")\n",
    "\n",
    "assert set(X_cat.columns) == set(cat_train.columns) == set(cat_test.columns)\n",
    "\n",
    "y = train[RESPONSE]\n",
    "\n",
    "(\n",
    "    X_cat_train,\n",
    "    X_cat_val,\n",
    "    X_num_train,\n",
    "    X_num_val,\n",
    "    y_train,\n",
    "    y_val\n",
    ") = train_test_split(\n",
    "    X_cat,\n",
    "    X_num,\n",
    "    y,\n",
    "    test_size=.33)\n",
    "\n",
    "X_val = np.hstack([X_cat_val, X_num_val])\n",
    "X_train = np.hstack([X_cat_train, X_num_train])\n",
    "\n",
    "assert X_cat_val.shape[0] == X_num_val.shape[0] == X_val.shape[0] == len(y_val)\n",
    "assert X_cat_train.shape[0] == X_num_train.shape[0] == X_train.shape[0] == len(y_train)\n",
    "assert X_cat_val.shape[1] == X_cat_train.shape[1]\n",
    "assert X_num_val.shape[1] == X_num_train.shape[1]\n",
    "assert X_val.shape[1] == X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, VotingRegressor\n",
    "\n",
    "def get_predictor_with_enc(encoder) -> Pipeline:\n",
    "    steps = [\n",
    "        ('encoder', encoder),\n",
    "        ('feature_selection', SelectFromModel(RandomForestRegressor(n_jobs=-1))),\n",
    "        ('regression', RandomForestRegressor(n_jobs=-1))\n",
    "    ]\n",
    "    return Pipeline(steps)\n",
    "\n",
    "def get_predictor() -> Pipeline:\n",
    "    steps = [\n",
    "        ('feature_selection', SelectFromModel(RandomForestRegressor(n_jobs=-1))),\n",
    "        ('regression', RandomForestRegressor(n_jobs=-1))\n",
    "    ]\n",
    "    return Pipeline(steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingRegressor(estimators=[('BackwardDifferenceEncoder',\n",
       "                               Pipeline(steps=[('encoder',\n",
       "                                                BackwardDifferenceEncoder()),\n",
       "                                               ('feature_selection',\n",
       "                                                SelectFromModel(estimator=RandomForestRegressor(n_jobs=-1))),\n",
       "                                               ('regression',\n",
       "                                                RandomForestRegressor(n_jobs=-1))])),\n",
       "                              ('BaseNEncoder',\n",
       "                               Pipeline(steps=[('encoder', BaseNEncoder()),\n",
       "                                               ('feature_selection',\n",
       "                                                SelectFromModel(estima...\n",
       "                               Pipeline(steps=[('encoder', PolynomialEncoder()),\n",
       "                                               ('feature_selection',\n",
       "                                                SelectFromModel(estimator=RandomForestRegressor(n_jobs=-1))),\n",
       "                                               ('regression',\n",
       "                                                RandomForestRegressor(n_jobs=-1))])),\n",
       "                              ('SumEncoder',\n",
       "                               Pipeline(steps=[('encoder', SumEncoder()),\n",
       "                                               ('feature_selection',\n",
       "                                                SelectFromModel(estimator=RandomForestRegressor(n_jobs=-1))),\n",
       "                                               ('regression',\n",
       "                                                RandomForestRegressor(n_jobs=-1))]))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from category_encoders import (\n",
    "    BackwardDifferenceEncoder,\n",
    "    BaseNEncoder,\n",
    "    CountEncoder,\n",
    "    HashingEncoder,\n",
    "    HelmertEncoder,\n",
    "    OrdinalEncoder,\n",
    "    OneHotEncoder,\n",
    "    PolynomialEncoder,\n",
    "    SumEncoder\n",
    ")\n",
    "\n",
    "encoders = [\n",
    "    BackwardDifferenceEncoder(),\n",
    "    BaseNEncoder(),\n",
    "    CountEncoder(),\n",
    "    HashingEncoder(),\n",
    "    HelmertEncoder(),\n",
    "    OrdinalEncoder(),\n",
    "    OneHotEncoder(),\n",
    "    PolynomialEncoder(),\n",
    "    SumEncoder()\n",
    "]\n",
    "\n",
    "predictors = [\n",
    "    (encoder.__class__.__name__, get_predictor_with_enc(encoder))\n",
    "    for encoder in  encoders]\n",
    "\n",
    "regr_cat = StackingRegressor(predictors)\n",
    "\n",
    "regr_cat.fit(X_cat_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: std bias=-0.006, std rmse=0.486\n",
      "num: std bias=-0.030, std rmse=0.520\n",
      "agg: std bias=-0.011, std rmse=0.437\n"
     ]
    }
   ],
   "source": [
    "regr_num = get_predictor()\n",
    "regr_num.fit(X_num_train, y_train)\n",
    "\n",
    "predictions_cat = regr_cat.predict(X_cat_val)\n",
    "predictions_num = regr_num.predict(X_num_val)\n",
    "\n",
    "errs = [\n",
    "    predictions_cat - y_val,\n",
    "    predictions_num - y_val\n",
    "]\n",
    "\n",
    "# These will live on past this cell, therefore capitalized.\n",
    "COVMAT = np.cov(errs)\n",
    "BIASES = [np.mean(arr) for arr in errs]\n",
    "VAL_RATIO = X_val.shape[0] / (X_val.shape[0] + X_train.shape[0])\n",
    "\n",
    "def aggregate_predictions(covmat, biases, predictions):\n",
    "    # Aggregate as if errors are independent\n",
    "    w = 1. / covmat.diagonal()\n",
    "    w /= sum(w)\n",
    "    return np.matmul(\n",
    "        w.T,\n",
    "        np.vstack([\n",
    "            prd - bias * VAL_RATIO\n",
    "            for prd, bias in zip(predictions, biases)\n",
    "        ])\n",
    "    )\n",
    "\n",
    "def aggregate_predictions_inv(covmat, biases, predictions):\n",
    "    # Aggregate taking covariances into account\n",
    "    w = np.linalg.inv(covmat).sum(axis=0)\n",
    "    w /= sum(w)\n",
    "    return np.matmul(\n",
    "        w.T,\n",
    "        np.vstack([\n",
    "            prd - bias * VAL_RATIO\n",
    "            for prd, bias in zip(predictions, biases)\n",
    "        ])\n",
    "    )\n",
    "\n",
    "predictions_agg = aggregate_predictions_inv(\n",
    "    COVMAT,\n",
    "    BIASES,\n",
    "    [predictions_cat, predictions_num])\n",
    "\n",
    "def evaluate(y_pred, y_true):\n",
    "    \"\"\"Evaluate predictions\"\"\"\n",
    "    err = y_pred - y_true\n",
    "    standardized_bias = np.mean(err) / np.std(y_true)\n",
    "    standardized_rmse = np.sqrt(np.mean(err * err)) / np.std(y_true)\n",
    "    return standardized_bias, standardized_rmse\n",
    "\n",
    "for prediction in [\n",
    "    {\"name\": \"cat\", \"predictions\": predictions_cat},\n",
    "    {\"name\": \"num\", \"predictions\": predictions_num},\n",
    "    {\"name\": \"agg\", \"predictions\": predictions_agg},\n",
    "]:\n",
    "    name = prediction[\"name\"]\n",
    "    predictions = prediction[\"predictions\"]\n",
    "    standardized_bias, standardized_rmse = evaluate(predictions, y_val)\n",
    "    print(f\"{name}: std bias={standardized_bias:.3f}, std rmse={standardized_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          SalePrice\n",
      "Id                 \n",
      "0     119772.479367\n",
      "1     152419.100533\n",
      "2     181710.942624\n",
      "3     187818.427587\n",
      "4     194800.017460\n",
      "...             ...\n",
      "1454   82169.150832\n",
      "1455   85595.879704\n",
      "1456  142465.351841\n",
      "1457  111075.005139\n",
      "1458  220658.371234\n",
      "\n",
      "[1459 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_num_test = test[FLOAT_COLS].astype(float).fillna(0.)\n",
    "X_cat_test = test[CATEGORICAL_COLS].astype(str).fillna(\"\")\n",
    "\n",
    "final_predictions_num = regr_num.predict(X_num_test)\n",
    "final_predictions_cat = regr_cat.predict(X_cat_test)\n",
    "\n",
    "final_predictions_agg = aggregate_predictions_inv(\n",
    "    COVMAT,\n",
    "    BIASES,\n",
    "    [final_predictions_cat, final_predictions_num])\n",
    "\n",
    "result = pd.DataFrame(\n",
    "    index=test.index,\n",
    "    columns=[RESPONSE],\n",
    "    data=final_predictions_agg.T)\n",
    "\n",
    "result.index.name = \"Id\"\n",
    "\n",
    "filename = RESULTS_DIR / \"submission.csv\"\n",
    "i = 0\n",
    "while filename.exists():\n",
    "    i += 1\n",
    "    filename = RESULTS_DIR / f\"submission_{i}.csv\"\n",
    "print(result)\n",
    "result.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e78a9480e413be1315ab0b461b67bf451de881cfba3b8c047d4173ea537f5e09"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
